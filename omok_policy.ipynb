{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import gym\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼 파라미터\n",
    "gridSize = 7\n",
    "nbActions = gridSize * gridSize\n",
    "nbStates = gridSize * gridSize\n",
    "\n",
    "LEARNING_RATE = 0.005\n",
    "INPUT = nbStates\n",
    "OUTPUT = nbActions\n",
    "DISCOUNT = 0.99\n",
    "\n",
    "winReward = 1\n",
    "\n",
    "STONE_NONE = 0\n",
    "STONE_PLAYER1 = 1\n",
    "STONE_PLAYER2 = -1\n",
    "STONE_MAX = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hiddenSize = 100\n",
    "maxMemory = 500\n",
    "batchSize = 50\n",
    "epoch = 100\n",
    "epsilonStart = 1\n",
    "epsilonDiscount = 0.999\n",
    "epsilonMinimumValue = 0.1\n",
    "discount = 0.9\n",
    "learningRate = 0.0001\n",
    "winReward = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Omok:\n",
    "    # --------------------------------\n",
    "    # 초기화\n",
    "    # --------------------------------\n",
    "    def __init__(self, gridSize):\n",
    "        self.gridSize = gridSize\n",
    "        self.nbStates = self.gridSize * self.gridSize\n",
    "        self.state = np.zeros(self.nbStates, dtype=np.uint8)\n",
    "        \n",
    "    # --------------------------------\n",
    "    # 리셋\n",
    "    # --------------------------------\n",
    "    def reset(self):\n",
    "        self.state = np.zeros(self.nbStates, dtype=np.uint8)\n",
    "        \n",
    "    # --------------------------------\n",
    "    # 현재 상태 구함\n",
    "    # --------------------------------\n",
    "    def getState(self):\n",
    "        return np.reshape(self.state, (1, self.nbStates))\n",
    "    \n",
    "    # --------------------------------\n",
    "    # render\n",
    "    # --------------------------------\n",
    "    def render(self):\n",
    "        state = np.reshape(self.state,(self.gridSize,self.gridSize))\n",
    "        print(state)\n",
    "        return state\n",
    "    \n",
    "    # --------------------------------\n",
    "    # 매칭 검사\n",
    "    # 다섯개 붙어 있으면 true, 아님 false\n",
    "    # --------------------------------\n",
    "    def CheckMatch(self, player):\n",
    "        for y in range(self.gridSize):\n",
    "            for x in range(self.gridSize):\n",
    "\n",
    "                # --------------------------------\n",
    "                # 오른쪽 검사\n",
    "                # --------------------------------\n",
    "                match = 0\n",
    "\n",
    "                for i in range(STONE_MAX):\n",
    "                    if (x + i >= self.gridSize):\n",
    "                        break\n",
    "\n",
    "                    if (self.state[y * self.gridSize + x + i] == player):\n",
    "                        match += 1\n",
    "                    else:\n",
    "                        break;\n",
    "\n",
    "                    if (match >= STONE_MAX):\n",
    "                        return True\n",
    "\n",
    "                # --------------------------------\n",
    "                # 아래쪽 검사\n",
    "                # --------------------------------\n",
    "                match = 0\n",
    "\n",
    "                for i in range(STONE_MAX):\n",
    "                    if (y + i >= self.gridSize):\n",
    "                        break\n",
    "\n",
    "                    if (self.state[(y + i) * self.gridSize + x] == player):\n",
    "                        match += 1\n",
    "                    else:\n",
    "                        break;\n",
    "\n",
    "                    if (match >= STONE_MAX):\n",
    "                        return True\n",
    "\n",
    "                # --------------------------------\n",
    "                # 오른쪽 대각선 검사\n",
    "                # --------------------------------\n",
    "                match = 0\n",
    "\n",
    "                for i in range(STONE_MAX):\n",
    "                    if ((x + i >= self.gridSize) or (y + i >= self.gridSize)):\n",
    "                        break\n",
    "\n",
    "                    if (self.state[(y + i) * self.gridSize + x + i] == player):\n",
    "                        match += 1\n",
    "                    else:\n",
    "                        break;\n",
    "\n",
    "                    if (match >= STONE_MAX):\n",
    "                        return True\n",
    "\n",
    "                # --------------------------------\n",
    "                # 왼쪽 대각선 검사\n",
    "                # --------------------------------\n",
    "                match = 0\n",
    "\n",
    "                for i in range(STONE_MAX):\n",
    "                    if ((x - i < 0) or (y + i >= self.gridSize)):\n",
    "                        break\n",
    "\n",
    "                    if (self.state[(y + i) * self.gridSize + x - i] == player):\n",
    "                        match += 1\n",
    "                    else:\n",
    "                        break;\n",
    "\n",
    "                    if (match >= STONE_MAX):\n",
    "                        return True\n",
    "\n",
    "        return False\n",
    "    \n",
    "    # --------------------------------\n",
    "    # 게임오버 검사\n",
    "    # 리워드를 리턴\n",
    "    # --------------------------------\n",
    "    def getReward(self, player):\n",
    "        if (self.CheckMatch(STONE_PLAYER1) == True):\n",
    "            if (player == STONE_PLAYER1):\n",
    "                return winReward\n",
    "            else:\n",
    "                return -winReward\n",
    "        elif (self.CheckMatch(STONE_PLAYER2) == True):\n",
    "            if (player == STONE_PLAYER1):\n",
    "                return -winReward\n",
    "            else:\n",
    "                return winReward\n",
    "        else:\n",
    "            for i in range(self.nbStates):\n",
    "                if (self.state[i] == STONE_NONE):\n",
    "                    return 0\n",
    "            return 0\n",
    "\n",
    "        \n",
    "    # --------------------------------\n",
    "    # action취해서 state update\n",
    "    # player : 다음 player로 전환\n",
    "    # --------------------------------\n",
    "    def getNextState(self, state, player, action):\n",
    "        state[action] = player;\n",
    "        self.state = state\n",
    "        player = -player\n",
    "        \n",
    "        return self.state, player\n",
    "    \n",
    "    \n",
    "    # --------------------------------\n",
    "    # 한 에피소드 동안 실행(게임이 끝날 때까지)\n",
    "    # --------------------------------\n",
    "    def step(self, sess):\n",
    "        trainExamples = []\n",
    "        self.curPlayer = 1\n",
    "        \n",
    "        while True:\n",
    "            #canonicalBoard = self.game.getCanonicalForm(self.state,self.curPlayer)\n",
    "            pi = sess.run(output_layer, feed_dict={X: self.state, keep_prob: 1.0})\n",
    "            \n",
    "            trainExamples.append([self.state, self.curPlayer, pi])\n",
    "            action = np.random.choice(len(pi), p=pi)\n",
    "            \n",
    "            self.state, self.curPlayer = self.getNextState(self.state, self.curPlayer, action)\n",
    "            \n",
    "            r = self.getReward(self.state, self.curPlayer)\n",
    "            \n",
    "            if r!=0:\n",
    "                return [(x[0],x[2],r*((-1)**(x[1]!=self.curPlayer))) for x in trainExamples]\n",
    "            \n",
    "                # 전체 에피소드 (한 수 한 수....)\n",
    "                # 각 수마다 state, policy, reward\n",
    "                # 마지막에 이긴 player가 둔 수에는 모두 r=1, 진 player가 둔 수는 모두 r=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# network architecture\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, nbStates])\n",
    "x_image = tf.reshape(X, [-1, gridSize, gridSize, 1])\n",
    "\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "W_conv1 = weight_variable([3, 3, 1, 32])\n",
    "b_conv1 = bias_variable([32])\n",
    "\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "W_conv2 = weight_variable([3, 3, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "W_fc1 = weight_variable([3 * 3 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 3*3*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "keep_prob = tf.placeholder(\"float\")\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "W_fc2 = weight_variable([1024, nbActions])\n",
    "b_fc2 = bias_variable([nbActions])\n",
    "\n",
    "output_layer=tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n",
    "\n",
    "Y = tf.placeholder(tf.float32, [None, nbActions])\n",
    "cost = tf.reduce_sum(tf.square(Y - output_layer)) / (2 * batchSize)\n",
    "optimizer = tf.train.AdamOptimizer(learningRate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
